#Deep Learning

### Do deep networks really need to be deep?
- It was proved that network with large enough hidden layer of sigmoid function can approximate any decision boudary.
- However, Deeper models were found to work better and easier to train in real-life setting
- In this paper, they provide evidence that shallow network are capable of learning the same functions as deepnet. Sometimes even with same number of parameters
- They used model compression to allow shallow model to mimic(*I don't know what this means*) deeper networks. However, they were not able to train shallow nets directly from input data. This shows that functions learned by deep nets are really not that deep(*I also don't know what deep in function context means*)
